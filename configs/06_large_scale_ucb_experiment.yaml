# VULCAN Configuration for Large-Scale Goodreads Experiment

api:
  host: localhost
  port: 8000
  reload: false # Set to false for stable, long-running experiments

llm:
  provider: openai
  model_name: gpt-4-turbo
  temperature: 0.7
  api_key_env: OPENAI_API_KEY

data:
  # Using the main goodreads DB and specifying the splits directory
  db_path: data/goodreads.db
  splits_dir: data/splits/
  # These will be iterated over by the experiment runner script
  outer_fold: 1
  inner_fold: 1
  # Use a large sample size appropriate for the full dataset
  sample_size: 500000

logging:
  level: INFO
  structured: true

evaluation:
  sample_size: 100000 # Larger validation sample for more stable rewards
  scoring_mode: cluster # Or another appropriate mode for the task

experiment:
  name: Goodreads_UCB_Large
  description: "Large-scale UCB experiment on Goodreads dataset, focusing on text-based feature generation from reviews."
  output_dir: experiments/goodreads_large_scale_ucb
  tensorboard_enabled: true
  wandb_enabled: true
  # Evolutionary Parameters from the protocol
  max_generations: 100
  population_size: 50
  generation_size: 2
  mutation_rate: 0.2
  ucb_exploration_constant: 2.0
  early_stopping_patience: 15 