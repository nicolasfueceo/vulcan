{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "Goodreads Fantasy Books Exploratory Data Analysis<br>\n",
    "------------------------------------------------<br>\n",
    "This script explores various aspects of the Goodreads fantasy books dataset:<br>\n",
    "1. Basic Statistics and Distributions<br>\n",
    "2. User Behavior Analysis<br>\n",
    "3. Book Characteristics<br>\n",
    "4. Network Analysis<br>\n",
    "Author: Nicolas<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import json\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set visualization style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "sns.set(font_scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/interim/goodreads/\"\n",
    "BOOKS_FILE = os.path.join(DATA_DIR, \"fantasy_books_filtered.json\")\n",
    "REVIEWS_FILE = os.path.join(DATA_DIR, \"fantasy_reviews_filtered.json\")\n",
    "INTERACTIONS_FILE = os.path.join(DATA_DIR, \"fantasy_interactions_filtered.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_in_chunks(filename, chunk_size=10000, max_rows=None):\n",
    "    \"\"\"Load JSON data in chunks for memory efficiency.\"\"\"\n",
    "    data = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        chunk = []\n",
    "        for i, line in enumerate(tqdm(f, desc=f\"Loading {os.path.basename(filename)}\")):\n",
    "            if max_rows and i >= max_rows:\n",
    "                break\n",
    "            if line.strip():\n",
    "                try:\n",
    "                    chunk.append(json.loads(line))\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "            if len(chunk) >= chunk_size:\n",
    "                data.extend(chunk)\n",
    "                chunk = []\n",
    "        if chunk:\n",
    "            data.extend(chunk)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_data(sample_size=1000):\n",
    "    \"\"\"Load sample data from all three datasets.\"\"\"\n",
    "    print(\"Loading samples of each dataset...\")\n",
    "    books_sample = load_json_in_chunks(BOOKS_FILE, max_rows=sample_size)\n",
    "    reviews_sample = load_json_in_chunks(REVIEWS_FILE, max_rows=sample_size)\n",
    "    interactions_sample = load_json_in_chunks(INTERACTIONS_FILE, max_rows=sample_size)\n",
    "\n",
    "    # Convert to dataframes\n",
    "    df_books = pd.DataFrame(books_sample)\n",
    "    df_reviews = pd.DataFrame(reviews_sample)\n",
    "    df_interactions = pd.DataFrame(interactions_sample)\n",
    "    return df_books, df_reviews, df_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_larger_data(books_max=None, reviews_max=50000, interactions_max=100000):\n",
    "    \"\"\"Load larger samples for analysis.\"\"\"\n",
    "    print(\"Loading larger dataset samples...\")\n",
    "\n",
    "    # Books dataset should be manageable in full\n",
    "    books_data = load_json_in_chunks(BOOKS_FILE, max_rows=books_max)\n",
    "    df_books = pd.DataFrame(books_data)\n",
    "    print(f\"Loaded {len(df_books)} books\")\n",
    "\n",
    "    # For interactions and reviews, load samples\n",
    "    interactions_data = load_json_in_chunks(\n",
    "        INTERACTIONS_FILE, max_rows=interactions_max\n",
    "    )\n",
    "    df_interactions = pd.DataFrame(interactions_data)\n",
    "    print(f\"Loaded {len(df_interactions)} interactions\")\n",
    "    reviews_data = load_json_in_chunks(REVIEWS_FILE, max_rows=reviews_max)\n",
    "    df_reviews = pd.DataFrame(reviews_data)\n",
    "    print(f\"Loaded {len(df_reviews)} reviews\")\n",
    "    return df_books, df_reviews, df_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data_structure(df_books, df_reviews, df_interactions):\n",
    "    \"\"\"Print information about the data structure.\"\"\"\n",
    "    print(\"\\n--- DATA STRUCTURE EXPLORATION ---\")\n",
    "    print(\"\\nBooks dataset schema:\")\n",
    "    print(df_books.columns.tolist())\n",
    "    print(\"\\nReviews dataset schema:\")\n",
    "    print(df_reviews.columns.tolist())\n",
    "    print(\"\\nInteractions dataset schema:\")\n",
    "    print(df_interactions.columns.tolist())\n",
    "    print(\"\\nSample books data:\")\n",
    "    print(df_books.head(2).to_string())\n",
    "    print(\"\\nSample reviews data:\")\n",
    "    print(df_reviews.head(2).to_string())\n",
    "    print(\"\\nSample interactions data:\")\n",
    "    print(df_interactions.head(2).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_user_activity(df_interactions, df_reviews):\n",
    "    \"\"\"Analyze user activity distribution.\"\"\"\n",
    "    print(\"\\n--- 1.1 USER ACTIVITY ANALYSIS ---\")\n",
    "\n",
    "    # Use reviews instead since interactions doesn't have user_id\n",
    "    user_interaction_counts = df_reviews[\"user_id\"].value_counts()\n",
    "\n",
    "    # Summary statistics\n",
    "    print(\"\\nUser Interaction Statistics:\")\n",
    "    print(f\"Total unique users: {len(user_interaction_counts)}\")\n",
    "    print(user_interaction_counts.describe())\n",
    "\n",
    "    # Visualize the distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Left plot: Regular histogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(user_interaction_counts, bins=50, kde=True)\n",
    "    plt.title(\"Distribution of Interactions per User\")\n",
    "    plt.xlabel(\"Number of Interactions\")\n",
    "    plt.ylabel(\"Count of Users\")\n",
    "\n",
    "    # Right plot: Log scale for better visualization of distribution tail\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(user_interaction_counts, bins=50, kde=True, log_scale=(False, True))\n",
    "    plt.title(\"Distribution of Interactions per User (Log Scale)\")\n",
    "    plt.xlabel(\"Number of Interactions\")\n",
    "    plt.ylabel(\"Count of Users (Log Scale)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"user_activity_distribution.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Show the most active users\n",
    "    print(\"\\nTop 10 Most Active Users:\")\n",
    "    print(user_interaction_counts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_book_popularity(df_interactions, df_books, df_reviews):\n",
    "    \"\"\"Analyze book popularity distribution.\"\"\"\n",
    "    print(\"\\n--- 1.2 BOOK POPULARITY ANALYSIS ---\")\n",
    "\n",
    "    # Use reviews for interaction counts instead\n",
    "    book_interaction_counts = df_reviews[\"book_id\"].value_counts()\n",
    "\n",
    "    # Summary statistics\n",
    "    print(\"\\nBook Interaction Statistics:\")\n",
    "    print(f\"Total unique books with interactions: {len(book_interaction_counts)}\")\n",
    "    print(book_interaction_counts.describe())\n",
    "\n",
    "    # Visualize the distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(book_interaction_counts, bins=50, kde=True)\n",
    "    plt.title(\"Distribution of Interactions per Book\")\n",
    "    plt.xlabel(\"Number of Interactions\")\n",
    "    plt.ylabel(\"Count of Books\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(book_interaction_counts, bins=50, kde=True, log_scale=(False, True))\n",
    "    plt.title(\"Distribution of Interactions per Book (Log Scale)\")\n",
    "    plt.xlabel(\"Number of Interactions\")\n",
    "    plt.ylabel(\"Count of Books (Log Scale)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"book_popularity_distribution.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Get the most popular books\n",
    "    try:\n",
    "        top_book_ids = book_interaction_counts.head(10).index.tolist()\n",
    "        popular_books = df_books[df_books[\"book_id\"].isin(top_book_ids)][\n",
    "            [\"book_id\", \"title\", \"authors\"]\n",
    "        ]\n",
    "\n",
    "        # Add interaction counts\n",
    "        popular_books_with_counts = popular_books.copy()\n",
    "        popular_books_with_counts[\"interaction_count\"] = popular_books_with_counts[\n",
    "            \"book_id\"\n",
    "        ].apply(lambda x: book_interaction_counts.get(x, 0))\n",
    "        popular_books_with_counts = popular_books_with_counts.sort_values(\n",
    "            \"interaction_count\", ascending=False\n",
    "        )\n",
    "        print(\"\\nTop 10 Most Popular Books:\")\n",
    "        print(popular_books_with_counts.to_string())\n",
    "    except KeyError as e:\n",
    "        print(f\"Could not identify popular books due to: {e}\")\n",
    "        print(\"Available columns in books dataset:\", df_books.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_rating_distribution(df_interactions, df_reviews):\n",
    "    \"\"\"Analyze rating distribution.\"\"\"\n",
    "    print(\"\\n--- 1.3 RATING DISTRIBUTION ANALYSIS ---\")\n",
    "\n",
    "    # Check if ratings are available in interactions or reviews\n",
    "    if \"rating\" in df_interactions.columns:\n",
    "        ratings = df_interactions[\"rating\"]\n",
    "        rating_source = \"interactions\"\n",
    "    elif \"rating\" in df_reviews.columns:\n",
    "        ratings = df_reviews[\"rating\"]\n",
    "        rating_source = \"reviews\"\n",
    "    else:\n",
    "        print(\"No rating column found in either interactions or reviews.\")\n",
    "        return\n",
    "\n",
    "    # Get basic statistics\n",
    "    print(f\"\\nRating Statistics (from {rating_source}):\")\n",
    "    print(ratings.describe())\n",
    "\n",
    "    # Plot the distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(ratings, bins=10, kde=True)\n",
    "    plt.title(\"Distribution of Ratings\")\n",
    "    plt.xlabel(\"Rating\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    rating_counts = ratings.value_counts().sort_index()\n",
    "    sns.barplot(x=rating_counts.index, y=rating_counts.values)\n",
    "    plt.title(\"Rating Distribution\")\n",
    "    plt.xlabel(\"Rating\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"rating_distribution.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_temporal_patterns(df_interactions, df_reviews):\n",
    "    \"\"\"Analyze temporal patterns in interactions.\"\"\"\n",
    "    print(\"\\n--- 1.4 TEMPORAL PATTERNS ANALYSIS ---\")\n",
    "\n",
    "    # Use reviews for temporal analysis instead of interactions\n",
    "    date_col = \"date_added\" if \"date_added\" in df_reviews.columns else None\n",
    "    if not date_col:\n",
    "        print(\"No date/time column found for temporal analysis.\")\n",
    "        return\n",
    "    try:\n",
    "        # Convert to datetime\n",
    "        df_reviews[date_col] = pd.to_datetime(df_reviews[date_col], errors=\"coerce\")\n",
    "\n",
    "        # Use reviews dataframe for the rest of the analysis\n",
    "        df_time = df_reviews.dropna(subset=[date_col])\n",
    "\n",
    "        # Create monthly time series\n",
    "        df_time[\"year_month\"] = df_time[date_col].dt.to_period(\"M\")\n",
    "        monthly_counts = df_time[\"year_month\"].value_counts().sort_index()\n",
    "        monthly_df = pd.DataFrame({\"count\": monthly_counts})\n",
    "        monthly_df.index = monthly_df.index.to_timestamp()\n",
    "\n",
    "        # Plot monthly trend\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.plot(\n",
    "            monthly_df.index, monthly_df[\"count\"], marker=\"o\", linestyle=\"-\", alpha=0.7\n",
    "        )\n",
    "        plt.title(\"Monthly Interactions with Fantasy Books\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Number of Interactions\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"monthly_interactions.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Yearly trend\n",
    "        df_time[\"year\"] = df_time[date_col].dt.year\n",
    "        yearly_counts = df_time[\"year\"].value_counts().sort_index()\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        yearly_counts.plot(kind=\"bar\")\n",
    "        plt.title(\"Yearly Interactions with Fantasy Books\")\n",
    "        plt.xlabel(\"Year\")\n",
    "        plt.ylabel(\"Number of Interactions\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"yearly_interactions.png\")\n",
    "        plt.close()\n",
    "        print(\"\\nTemporal analysis completed and saved as images.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in temporal analysis: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_user_reading_patterns(df_reviews):\n",
    "    \"\"\"Analyze user reading patterns over time.\"\"\"\n",
    "    print(\"\\n--- 2.1 USER READING PATTERNS ANALYSIS ---\")\n",
    "\n",
    "    # Check for date column in reviews instead of interactions\n",
    "    date_col = \"date_added\" if \"date_added\" in df_reviews.columns else None\n",
    "    if not date_col:\n",
    "        print(\"No date/time column found for reading pattern analysis.\")\n",
    "        return\n",
    "    try:\n",
    "        # Convert to datetime\n",
    "        df_reviews[date_col] = pd.to_datetime(df_reviews[date_col], errors=\"coerce\")\n",
    "\n",
    "        # Drop rows with invalid dates\n",
    "        df_time = df_reviews.dropna(subset=[date_col])\n",
    "\n",
    "        # Group by user and month\n",
    "        df_time[\"year_month\"] = df_time[date_col].dt.to_period(\"M\")\n",
    "        books_per_user_per_month = (\n",
    "            df_time.groupby([\"user_id\", \"year_month\"])[\"book_id\"].count().reset_index()\n",
    "        )\n",
    "        books_per_user_per_month.columns = [\"user_id\", \"year_month\", \"books_count\"]\n",
    "\n",
    "        # Calculate average books per user per month\n",
    "        avg_books_per_month = books_per_user_per_month[\"books_count\"].mean()\n",
    "        median_books_per_month = books_per_user_per_month[\"books_count\"].median()\n",
    "        print(f\"\\nAverage books per user per month: {avg_books_per_month:.2f}\")\n",
    "        print(f\"Median books per user per month: {median_books_per_month:.2f}\")\n",
    "\n",
    "        # Plot distribution\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.histplot(books_per_user_per_month[\"books_count\"], bins=30, kde=True)\n",
    "        plt.axvline(\n",
    "            avg_books_per_month,\n",
    "            color=\"red\",\n",
    "            linestyle=\"--\",\n",
    "            label=f\"Mean = {avg_books_per_month:.2f}\",\n",
    "        )\n",
    "        plt.axvline(\n",
    "            median_books_per_month,\n",
    "            color=\"green\",\n",
    "            linestyle=\"-\",\n",
    "            label=f\"Median = {median_books_per_month:.2f}\",\n",
    "        )\n",
    "        plt.title(\"Distribution of Books Read per User per Month\")\n",
    "        plt.xlabel(\"Number of Books\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"books_per_month_distribution.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Yearly analysis\n",
    "        df_time[\"year\"] = df_time[date_col].dt.year\n",
    "        books_per_user_per_year = (\n",
    "            df_time.groupby([\"user_id\", \"year\"])[\"book_id\"].count().reset_index()\n",
    "        )\n",
    "        books_per_user_per_year.columns = [\"user_id\", \"year\", \"books_count\"]\n",
    "        avg_books_per_year = books_per_user_per_year[\"books_count\"].mean()\n",
    "        median_books_per_year = books_per_user_per_year[\"books_count\"].median()\n",
    "        print(f\"\\nAverage books per user per year: {avg_books_per_year:.2f}\")\n",
    "        print(f\"Median books per user per year: {median_books_per_year:.2f}\")\n",
    "        print(\"\\nReading patterns analysis completed and saved as images.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in reading patterns analysis: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_user_rating_behavior(df_interactions, df_reviews):\n",
    "    \"\"\"Analyze user rating behavior.\"\"\"\n",
    "    print(\"\\n--- 2.2 USER RATING BEHAVIOR ANALYSIS ---\")\n",
    "\n",
    "    # Check if ratings are available\n",
    "    if \"rating\" in df_interactions.columns and \"user_id\" in df_interactions.columns:\n",
    "        df_ratings = df_interactions[[\"user_id\", \"book_id\", \"rating\"]].dropna(\n",
    "            subset=[\"rating\"]\n",
    "        )\n",
    "        rating_source = \"interactions\"\n",
    "    elif \"rating\" in df_reviews.columns and \"user_id\" in df_reviews.columns:\n",
    "        df_ratings = df_reviews[[\"user_id\", \"book_id\", \"rating\"]].dropna(\n",
    "            subset=[\"rating\"]\n",
    "        )\n",
    "        rating_source = \"reviews\"\n",
    "    else:\n",
    "        print(\"No rating data available for user rating behavior analysis.\")\n",
    "        return\n",
    "    try:\n",
    "        # Calculate user rating statistics\n",
    "        user_rating_stats = (\n",
    "            df_ratings.groupby(\"user_id\")[\"rating\"]\n",
    "            .agg([\"count\", \"mean\", \"std\", \"min\", \"max\"])\n",
    "            .reset_index()\n",
    "        )\n",
    "        user_rating_stats = user_rating_stats[\n",
    "            user_rating_stats[\"count\"] >= 5\n",
    "        ]  # Users with at least 5 ratings\n",
    "        print(f\"\\nUser Rating Behavior Statistics (from {rating_source}):\")\n",
    "        print(user_rating_stats.describe().to_string())\n",
    "\n",
    "        # Plot distribution of mean ratings\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.histplot(user_rating_stats[\"mean\"], bins=30, kde=True)\n",
    "        plt.title(\"Distribution of User Average Ratings\")\n",
    "        plt.xlabel(\"Average Rating\")\n",
    "        plt.ylabel(\"Count of Users\")\n",
    "        plt.savefig(\"user_mean_ratings_distribution.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Plot distribution of rating standard deviations\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.histplot(user_rating_stats[\"std\"].dropna(), bins=30, kde=True)\n",
    "        plt.title(\"Distribution of User Rating Standard Deviations\")\n",
    "        plt.xlabel(\"Standard Deviation\")\n",
    "        plt.ylabel(\"Count of Users\")\n",
    "        plt.savefig(\"user_rating_std_distribution.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # User rating bias\n",
    "        overall_mean_rating = df_ratings[\"rating\"].mean()\n",
    "        user_rating_stats[\"rating_bias\"] = (\n",
    "            user_rating_stats[\"mean\"] - overall_mean_rating\n",
    "        )\n",
    "        print(f\"\\nOverall mean rating: {overall_mean_rating:.2f}\")\n",
    "        print(\n",
    "            \"\\nTop 5 Users with Positive Rating Bias (rate books higher than average):\"\n",
    "        )\n",
    "        print(\n",
    "            user_rating_stats.nlargest(5, \"rating_bias\")[\n",
    "                [\"user_id\", \"count\", \"mean\", \"rating_bias\"]\n",
    "            ].to_string()\n",
    "        )\n",
    "        print(\n",
    "            \"\\nTop 5 Users with Negative Rating Bias (rate books lower than average):\"\n",
    "        )\n",
    "        print(\n",
    "            user_rating_stats.nsmallest(5, \"rating_bias\")[\n",
    "                [\"user_id\", \"count\", \"mean\", \"rating_bias\"]\n",
    "            ].to_string()\n",
    "        )\n",
    "        print(\"\\nUser rating behavior analysis completed and saved as images.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in user rating behavior analysis: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_genre_distribution(df_books):\n",
    "    \"\"\"Analyze genre distribution in books.\"\"\"\n",
    "    print(\"\\n--- 3.1 GENRE DISTRIBUTION ANALYSIS ---\")\n",
    "\n",
    "    # Look for genre information\n",
    "    genre_cols = [\n",
    "        col\n",
    "        for col in df_books.columns\n",
    "        if \"genre\" in col.lower() or \"categor\" in col.lower()\n",
    "    ]\n",
    "    genre_col = genre_cols[0] if genre_cols else None\n",
    "    if not genre_col:\n",
    "        print(\"No genre information found in books dataset.\")\n",
    "        # Try to find genres in other ways (e.g., in book tags or shelves)\n",
    "        alt_genre_cols = [\n",
    "            col\n",
    "            for col in df_books.columns\n",
    "            if \"tag\" in col.lower() or \"shelf\" in col.lower()\n",
    "        ]\n",
    "        genre_col = alt_genre_cols[0] if alt_genre_cols else None\n",
    "        if not genre_col:\n",
    "            print(\"No alternative genre information found.\")\n",
    "            return\n",
    "    try:\n",
    "        print(f\"Using '{genre_col}' for genre analysis.\")\n",
    "\n",
    "        # Extract genres - handling different possible data structures\n",
    "        genres = []\n",
    "        for genre_data in df_books[genre_col]:\n",
    "            if isinstance(genre_data, list):\n",
    "                genres.extend(genre_data)\n",
    "            elif isinstance(genre_data, str):\n",
    "                try:\n",
    "                    # Try to parse as JSON if it's a string representation of a list\n",
    "                    parsed = json.loads(genre_data)\n",
    "                    if isinstance(parsed, list):\n",
    "                        genres.extend(parsed)\n",
    "                    else:\n",
    "                        genres.append(genre_data)\n",
    "                except:\n",
    "                    genres.append(genre_data)\n",
    "            elif isinstance(genre_data, dict):\n",
    "                genres.extend(genre_data.keys())\n",
    "\n",
    "        # Count genres\n",
    "        genre_counts = Counter(genres)\n",
    "\n",
    "        # Get top genres\n",
    "        top_genres = genre_counts.most_common(20)\n",
    "        print(\"\\nTop 20 Genres:\")\n",
    "        for genre, count in top_genres:\n",
    "            print(f\"{genre}: {count}\")\n",
    "\n",
    "        # Plot genre distribution\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        genre_df = pd.DataFrame(top_genres, columns=[\"Genre\", \"Count\"])\n",
    "        sns.barplot(x=\"Count\", y=\"Genre\", data=genre_df)\n",
    "        plt.title(\"Top 20 Genres in Fantasy Books\")\n",
    "        plt.xlabel(\"Count\")\n",
    "        plt.ylabel(\"Genre\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"genre_distribution.png\")\n",
    "        plt.close()\n",
    "        print(\"\\nGenre distribution analysis completed and saved as image.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in genre distribution analysis: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_publication_trends(df_books):\n",
    "    \"\"\"Analyze publication year trends.\"\"\"\n",
    "    print(\"\\n--- 3.2 PUBLICATION YEAR TRENDS ---\")\n",
    "\n",
    "    # Find publication year column\n",
    "    pub_year_cols = [\n",
    "        col\n",
    "        for col in df_books.columns\n",
    "        if (\"year\" in col.lower() and \"pub\" in col.lower())\n",
    "        or \"published\" in col.lower()\n",
    "    ]\n",
    "    pub_year_col = pub_year_cols[0] if pub_year_cols else None\n",
    "    if not pub_year_col:\n",
    "        print(\"No publication year column found.\")\n",
    "        return\n",
    "    try:\n",
    "        # Extract years as integers\n",
    "        years = pd.to_numeric(df_books[pub_year_col], errors=\"coerce\")\n",
    "        valid_years = years[(years > 1800) & (years <= dt.datetime.now().year)]\n",
    "        print(\"\\nPublication Year Statistics:\")\n",
    "        print(valid_years.describe())\n",
    "\n",
    "        # Plot publication year distribution\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        sns.histplot(valid_years, bins=30, kde=True)\n",
    "        plt.title(\"Distribution of Publication Years\")\n",
    "        plt.xlabel(\"Publication Year\")\n",
    "        plt.ylabel(\"Count of Books\")\n",
    "        plt.savefig(\"publication_year_distribution.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Analyze ratings by publication decade if rating data is available in books\n",
    "        if \"average_rating\" in df_books.columns:\n",
    "            df_books[\"publication_decade\"] = (valid_years // 10) * 10\n",
    "            decade_ratings = df_books.groupby(\"publication_decade\")[\n",
    "                \"average_rating\"\n",
    "            ].mean()\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            decade_ratings.plot(kind=\"bar\")\n",
    "            plt.title(\"Average Rating by Publication Decade\")\n",
    "            plt.xlabel(\"Publication Decade\")\n",
    "            plt.ylabel(\"Average Rating\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\"ratings_by_decade.png\")\n",
    "            plt.close()\n",
    "            print(\"\\nAverage Rating by Publication Decade:\")\n",
    "            print(decade_ratings)\n",
    "        print(\"\\nPublication trends analysis completed and saved as images.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in publication trends analysis: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Explore the Data Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books_sample, df_reviews_sample, df_interactions_sample = load_sample_data()\n",
    "explore_data_structure(df_books_sample, df_reviews_sample, df_interactions_sample)\n",
    "df_books, df_reviews, df_interactions = load_larger_data()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_user_activity(df_interactions_sample, df_reviews_sample)\n",
    "analyze_book_popularity(df_interactions_sample, df_books_sample, df_reviews_sample)\n",
    "analyze_rating_distribution(df_interactions_sample, df_reviews_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Book Characteristics Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_genre_distribution(df_books)\n",
    "analyze_publication_trends(df_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run all analyses.\"\"\"\n",
    "    print(\"=== GOODREADS FANTASY BOOKS EXPLORATORY DATA ANALYSIS ===\")\n",
    "\n",
    "    # Create output directory for plots if it doesn't exist\n",
    "    if not os.path.exists(\"plots\"):\n",
    "        os.makedirs(\"plots\")\n",
    "    try:\n",
    "        # Load sample data first to understand structure\n",
    "        df_books_sample, df_reviews_sample, df_interactions_sample = load_sample_data()\n",
    "\n",
    "        # Explore data structure\n",
    "        explore_data_structure(\n",
    "            df_books_sample, df_reviews_sample, df_interactions_sample\n",
    "        )\n",
    "\n",
    "        # Load larger datasets for analysis\n",
    "        df_books, df_reviews, df_interactions = load_larger_data()\n",
    "\n",
    "        # 1. Basic Statistics and Distributions\n",
    "        analyze_user_activity(df_interactions, df_reviews)\n",
    "        analyze_book_popularity(df_interactions, df_books, df_reviews)\n",
    "        analyze_rating_distribution(df_interactions, df_reviews)\n",
    "        analyze_temporal_patterns(df_interactions, df_reviews)\n",
    "\n",
    "        # 2. User Behavior Analysis\n",
    "        analyze_user_reading_patterns(df_reviews)\n",
    "        analyze_user_rating_behavior(df_interactions, df_reviews)\n",
    "\n",
    "        # 3. Book Characteristics Analysis\n",
    "        analyze_genre_distribution(df_books)\n",
    "        analyze_publication_trends(df_books)\n",
    "        print(\"\\n=== ANALYSIS COMPLETE ===\")\n",
    "        print(\"All visualizations have been saved as PNG files.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
