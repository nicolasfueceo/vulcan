# VULCAN Recommender System Configuration

# Data Paths
data_paths:
  train_db: "data/goodreads.db"
  test_db: "data/test.db"
  validation_db: "data/validation.db"
  splits_dir: "data/splits"
  queries_dir: "data/queries"
  models_dir: "models"
  features_dir: "features"
  logs_dir: "logs"

# Data Splitting
data_splits:
  test_size: 0.2            # Outer test set size (20% of all users)
  outer_folds: 5            # K-fold for outer CV
  inner_folds: 3            # M-fold for inner CV
  random_state: 42          # Random seed for reproducibility
  min_ratings_per_user: 5   # Minimum number of ratings a user must have

# Phase 1: MCTS-Driven LLM Feature Engineering
phase1:
  # MCTS Configuration
  mcts:
    budget: 100              # Number of MCTS iterations per feature
    exploration_weight: 1.0  # UCT exploration weight (C)
    rollout_depth: 2         # Number of random features to add in rollout
    max_iterations: 20       # Maximum number of features to add
    memory_buffer_size: 10   # Number of best features to keep in memory

  # LLM Configuration
  llm:
    model: "gpt-4"           # LLM model to use
    temperature: 0.7         # Sampling temperature
    max_tokens: 1000         # Maximum tokens in response
    prompt_template: "prompts/feature_engineering.txt"  # Template for feature generation
    sandbox_timeout: 5       # Seconds before timing out feature execution

  # Feature Evaluation
  feature_evaluation:
    model_type: "lightfm"    # Model to use for feature evaluation
    metrics: ["rmse", "precision@10", "recall@10"]  # Metrics to track
    lightfm:
      no_components: 30      # Latent dimensionality
      learning_rate: 0.05    # Learning rate
      loss: "warp"           # Loss function
      max_sampled: 10        # Maximum number of negative samples
      epochs: 20             # Training epochs

  # Clustering
  clustering:
    method: "kmeans"         # Clustering method
    n_clusters_range: [3, 5, 7, 10, 15]  # Cluster count options to try
    max_iter: 300            # Maximum k-means iterations
    n_init: 10               # Number of k-means runs with different seeds
    random_state: 42         # Random seed for k-means

# Phase 2: Conversational Cold-Start Assignment
phase2:
  # Question Selection
  question_selection:
    method: "information_gain"  # "information_gain" or "mcts"
    top_k_features: 20          # Number of top features to consider for questions
    min_mi_threshold: 0.01      # Minimum mutual information to be a candidate

  # MCTS Dialog Planning (optional)
  mcts_dialog:
    budget: 50                  # MCTS iterations per question
    exploration_weight: 1.0     # UCT exploration weight
    planning_horizon: 5         # Number of questions to look ahead
    entropy_weight: 1.0         # Weight for entropy reduction in reward

  # Dialog Control
  dialog:
    max_questions: 10           # Maximum questions to ask a user
    min_confidence: 0.7         # Confidence threshold to stop asking questions
    min_entropy: 0.5            # Entropy threshold to stop asking questions

# Logging & Reproducibility
logging:
  level: "INFO"                 # Logging level
  save_prompts: true            # Whether to save LLM prompts
  save_responses: true          # Whether to save LLM responses
  save_features: true           # Whether to save generated features
  save_mcts_stats: true         # Whether to save MCTS statistics 