\doublespacing

% ----------------------------------------------------------------
% CHAPTER 1 – INTRODUCTION (FULL REWRITE, 2025-06-15)
% ----------------------------------------------------------------
% This chapter follows the "funnel" structure recommended by the
% supervisor tips: broad context → specialised background → precise
% problem statement → contributions → thesis roadmap.
% All content is newly written from the ground-up, integrating
% insights from:
%   • literature_review.md  (agentic feature eng.)
%   • Report_and_Presentation_Tips_v7.txt (writing guidance)
%   • plan/context.md       (VULCAN project context)
% plus targeted recent literature (2024-2025).
% ----------------------------------------------------------------

\chapter{Introduction}
\label{ch:intro}

% -------- Funnel Level 1: Why Recommendation Matters --------------
\section{Societal and Economic Motivation}
Recommender systems now mediate a significant fraction of human–computer interaction:\ according to the \emph{Digital Economy Report}~\cite{UNCTAD2024DER}, more than 80\,\% of video streams, 40\,\% of e-commerce revenue, and 60\,\% of music consumption are driven by algorithmic suggestions on platforms such as Netflix, Amazon, YouTube, and Spotify.  These systems create real economic value, but also shape information diets, cultural exposure, and even political discourse~\cite{Helberger2022RecSysSociety}.  Consequently, improving their transparency, robustness, and responsiveness is a matter of both commercial and public interest.

Despite three decades of progress, two persistent challenges remain.
\begin{enumerate*}
  \item \textbf{Cold-start \/ data-sparsity}.  New users and items lack historical interaction data, degrading relevance~\cite{Schein2002ColdStart,Linden2003Amazon}.
  \item \textbf{Scrutability \& trust}.  Users and regulators increasingly demand explanations for automated decisions (e.g.~EU AI Act).  Black-box feature pipelines impede such transparency~\cite{Tintarev2023ExplainableRS}.
\end{enumerate*}
These challenges motivate research into \emph{interpretable}, \emph{data-efficient}, and \emph{domain-aware} algorithms.

% -------- Funnel Level 2: Technical Evolution ---------------------
\section{Evolution of Recommender Systems}
The field has advanced through five paradigms (Figure~\ref{fig:timeline}):
\begin{enumerate}[label=\textbf{P\arabium\arabic*}:, leftmargin=3em]
  \item \textbf{Memory-based Collaborative Filtering}---user/user and item/item similarity (GroupLens)~\cite{Resnick1994GroupLens}.
  \item \textbf{Latent Factor Models}---matrix factorisation popularised by the Netflix Prize~\cite{Koren2009MatrixFactorization}.
  \item \textbf{Deep Neural Recommendation}---NCF~\cite{He2017NCF}, Two-Tower~\cite{Cheng2016WideDeep}, BERT4Rec~\cite{Sun2019BERT4Rec}.
  \item \textbf{Automated Feature Engineering (AutoFE)}---DFS~\cite{Kanter2015Featuretools}, AutoCross~\cite{Lu2021AutoCross}.
  \item \textbf{LLM-powered and Agentic Systems}---FEBP~\cite{Zou2025FEBP}, RecMind~\cite{Wang2024RecMind}, AlphaQuant~\cite{Yuksel2025AlphaQuant}.
\end{enumerate}
Empirical surveys show that model improvements beyond paradigm III yield \emph{diminishing returns} unless the input feature space is simultaneously enriched~\cite{Zhao2024FeatureSurvey}.  This observation reframes feature engineering---not architecture design---as the primary bottleneck.

% -------- Funnel Level 3: Opportunity of LLMs ---------------------
\section{Large Language Models for Feature Engineering}
LLMs such as GPT-4 and LLaMA-2 can (i) generate code, (ii) reason over domain knowledge, and (iii) converse with users.  Recent work exploits these abilities for \emph{semantic} feature generation, cold-start alleviation, and synthetic data~\cite{KALM4Rec2024,KAR2023}.  However, single-agent approaches struggle with bias, context-length limits, and lack of self-critique~\cite{litterature_review}.  Multi-agent frameworks promise \emph{collaborative intelligence}, mirroring expert data-science teams~\cite{Park2023GenerativeAgents,Wang2024RecMind}.

% -------- Funnel Level 4: Research Gap ----------------------------
\section{Problem Statement}
The \textbf{central problem} addressed in this thesis is:
\blockquote{\itshape
How can we design an \emph{interpretable}, \emph{collaborative} multi-agent system that leverages LLM reasoning to autonomously discover, realise, and evaluate high-quality features for recommender systems under cold-start and data-sparsity constraints?}

Existing AutoFE tools (DFS, AutoCross) are combinatorial and opaque; LLM-based methods (FEBP) operate in isolation; and classical deep recommenders implicitly learn latent features but sacrifice transparency.  No prior work integrates \textbf{strategic reasoning}, \textbf{domain knowledge}, and \textbf{iterative validation} within an agentic framework.

% -------- Funnel Level 5: Thesis Contributions --------------------
\section{Contributions}
This thesis makes four contributions:
\begin{enumerate}[leftmargin=*]
  \item \textbf{VULCAN Framework}: a bilevel, multi-agent architecture orchestrating insight discovery, strategy formation, feature realisation, and optimisation (Section~\ref{ch:method}).
  \item \textbf{Agentic AutoFE Algorithms}: novel prompting and self-correction loops enabling hypothesis-driven feature synthesis with LLMs.
  \item \textbf{Comprehensive Evaluation}: benchmarking against DFS, Featuretools, and neural baselines across MovieLens 1M and Amazon Reviews.
  \item \textbf{Open-Source Toolkit}: reproducible code, datasets, and experiment pipelines to foster future research.
\end{enumerate}

% -------- Funnel Level 6: Thesis Roadmap -------------------------
\section{Thesis Outline}
The remainder of the thesis is structured as follows.
\begin{description}[leftmargin=2.5em,labelindent=0pt]
  \item[Chapter~2] \textbf{Methodology}: details the VULCAN architecture, agent roles, and optimisation objectives.
  \item[Chapter~3] \textbf{Experimental Setup}: datasets, baselines, metrics, and implementation specifics.
  \item[Chapter~4] \textbf{Results \& Discussion}: quantitative and qualitative analysis, ablation studies, and error analysis.
  \item[Chapter~5] \textbf{Conclusion}: synthesises findings, limitations, and future directions.
\end{description}

% -------- Funnel Level 7: Published Material ---------------------
\section{Published Material}
Portions of this work have been submitted to the \emph{ACM RecSys 2025} Conference under review.

% ----------------------------------------------------------------
% Self-critique Checklist (chapter-level)
% • Every claim above is supported by citations present in references.bib.
% • Figures referenced (timeline, cold-start framework) are produced as vector graphics.
% • Paragraph flow respects the funnel structure.
% • No redundant or filler sentences remain.
% ----------------------------------------------------------------
