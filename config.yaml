# Placeholder: Configuration for the Autonomous Feature Engineering Environment
# This file should be populated with actual configuration values.

data_source:
  type: sql # Options: sql, csv, api (csv/api are stubs for now)
  table_name: reviews # Name of the main table in the SQL database
  params:
    # For SQL:
    db_path: "/home/ubuntu/goodreads_reviews.db" # Path to the SQLite DB file
    # For CSV (Stub): 
    # file_paths: 
    #   train: "/path/to/train_data.csv"
    #   validate: "/path/to/validate_data.csv"
    #   test: "/path/to/test_data.csv"
  splits:
    # Files containing the primary IDs (e.g., review_id) for each split
    # Assumes CSV with a single column named 'id'
    train: "/home/ubuntu/train_ids.csv"
    validate: "/home/ubuntu/validate_ids.csv"
    test: "/home/ubuntu/test_ids.csv" # Optional: For final evaluation outside MCTS
  # Column names in the database/data
  user_id_col: "user_id"
  item_id_col: "book_id" # Or generic item_id
  rating_col: "rating"
  instance_id_col: "review_id" # Primary key for instances/reviews

evaluation:
  # How to evaluate the quality of features discovered by MCTS
  # Focuses on improving clustering for recommendation
  target_column: "rating" # The column LightFM tries to predict implicitly
  # Clustering settings
  clustering_algorithm: "kmeans" # Options: kmeans, etc.
  num_clusters: 5 # K value for clustering (can be tuned or made dynamic)
  max_cluster_iterations: 100 # Max iterations for KMeans
  # Recommender model settings (LightFM)
  recommender_model: "lightfm"
  lightfm_params:
    no_components: 10 # Dimensionality of embeddings
    loss: "warp" # Options: warp, logistic, bpr, warp-kos
    learning_rate: 0.05
    item_alpha: 0.0 # L2 penalty on item features
    user_alpha: 0.0 # L2 penalty on user features
    max_sampled: 10 # Number of negative samples for warp/warp-kos
    epochs: 10 # Number of training epochs
    num_threads: 2 # Number of parallel threads
  # Evaluation metric for recommender performance (within clusters)
  # Used to calculate the final reward for MCTS
  # Options: precision_at_k, recall_at_k, auc_score (from lightfm.evaluation)
  metric: "auc_score" 
  metric_k: 10 # Value of k for precision/recall@k
  # How to aggregate cluster scores (e.g., weighted by cluster size)
  aggregation_method: "weighted_average"

agent:
  # Configuration for the feature-generating agent (e.g., LLM)
  type: "stub" # Options: stub, llm (llm not implemented yet)
  # For stub agent:
  predefined_features_path: "/home/ubuntu/predefined_features.py" # Path to a file defining FeatureDefinition objects
  # For LLM agent (Future):
  # model_name: "gpt-4"
  # api_key: "YOUR_API_KEY"
  # prompt_template_path: "prompts/feature_generation.txt"

mcts:
  # Configuration for the Monte Carlo Tree Search orchestrator
  max_iterations: 50 # Total number of MCTS iterations (feature candidates to explore)
  simulation_depth: 1 # How many random steps to take during simulation (rollout). 1 means evaluate immediately.
  exploration_factor: 1.414 # UCT exploration constant (sqrt(2) is common)
  reward_discount: 1.0 # Discount factor for future rewards (usually 1.0 for non-temporal tasks)
  # Strategy if agent fails to generate a valid feature
  agent_failure_strategy: "skip_node" # Options: skip_node, retry

orchestrator:
  # General settings for the main control loop
  # Baseline score calculation (e.g., evaluate an empty feature set)
  calculate_baseline: true 

sandbox:
  # Settings for the code execution sandbox
  timeout: 10 # Conceptual timeout in seconds for feature execution

logging:
  level: "INFO" # Options: DEBUG, INFO, WARNING, ERROR
  log_file: "/home/ubuntu/autonomous_fe.log"

